---
title: Advent of Code 2024
description: A log of my experience with Advent of Code 2024, there are spoilers in here so beware.
date: 2024-12-11
ogImage: /blog-og-images/aoc-2024.png
published: true
keywords:
    [
        "advent of code 2024",
        "advent of code solutions 2024",
        "aoc 2024 solutions",
        "advent of code 2024 answers",
        "advent of code 2024 day 1 solution",
        "advent of code 2024 day 2 solution",
        "advent of code 2024 day 3 solution",
        "advent of code 2024 day 4 solution",
        "advent of code 2024 day 5 solution",
        "advent of code 2024 day 6 solution",
        "advent of code 2024 day 7 solution",
        "advent of code 2024 day 8 solution",
        "advent of code 2024 day 9 solution",
        "advent of code 2024 day 10 solution",
        "advent of code 2024 day 11 solution",
        "aoc 2024 golang solutions",
        "advent of code go",
        "advent of code 2024 explained",
        "advent of code 2024 go",
        "advent of code 2024 walkthrough",
        "how to solve advent of code 2024",
        "programming puzzles",
        "coding challenges 2024",
        "go programming exercises",
        "daily coding problems",
        "algorithmic puzzles",
        "historian hysteria",
        "red-nosed reports",
        "mull it over",
        "ceres search",
        "print queue",
        "guard gallivant",
        "bridge repair",
        "resonant collinearity",
        "disk fragmenter",
        "hoof it",
        "plutonian pebbles",
        "go optimization",
        "algorithm complexity",
        "advent of code 2024 tips",
        "aoc 2024 hints"
    ]
---

import Callout from "../../components/Callout.astro";

<br />

<Callout type="none">
    All of my Advent of Code solutions are available on
    [GitHub](https://github.com/dickeyy/adventofcode/tree/main/2024).
</Callout>

## Day 11: Plutonian Pebbles

Today's puzzle involved some physics-defying stones that transform based on simple rules whenever
you blink. Each stone has a number, and depending on whether it's 0, has an even number of digits,
or neither, it will either become 1, split into two stones, or multiply by 2024.

For Part 1, we need to simulate 25 "blinks" and count how many stones we end up with. My first
approach was pretty straightforward - just track each stone in a slice and apply the
transformations:

```go
func blink(stones []int) []int {
    newStones := make([]int, 0)
    for _, stone := range stones {
        if stone == 0 {
            newStones = append(newStones, 1)
        } else if countDigitsInNumber(stone)%2 == 0 {
            left, right := splitNumberIntoHalves(stone)
            newStones = append(newStones, left, right)
        } else {
            newStones = append(newStones, stone*2024)
        }
    }
    return newStones
}
```

This worked fine for Part 1, but when Part 2 asked for 75 iterations, the exponential growth of
stones made this approach impractical. After some thinking, I realized I could optimize by tracking
frequencies instead of individual stones. This led to recasting the problem in terms of stone
counts:

```go
func day11(input string, part int) int {
    s := utils.GetIntsInString(input)

    // count freq of each stone val
    scs := make(map[int]int)
    for _, s := range s {
        scs[s]++
    }

    iters := 25
    if part == 2 {
        iters = 75
    }

    // process stones
    for i := 0; i < iters; i++ {
        scs = blinkAllStones(scs)
    }

    return sumStones(scs)
}
```

The core transformation logic became simpler too, just handling one stone value at a time:

```go
func blinkOnce(stone int) []int {
    if stone == 0 {
        return []int{1}
    }

    // convert to string to check digits
    s := strconv.Itoa(stone)
    if len(s)%2 == 0 {
        // split into two halves
        halfway := len(s) / 2
        l := utils.AtoiNoErr(s[:halfway])
        r := utils.AtoiNoErr(s[halfway:])
        return []int{l, r}
    }

    return []int{stone * 2024}
}
```

With the `blinkAllStones` function looking like this:

```go
func blinkAllStones(stoneCount map[int]int) map[int]int {
    nc := make(map[int]int)

    for s, c := range stoneCount {
        // get new stones from transformation
        ns := blinkOnce(s)
        // add to counts, multiplied by how many of oritinal stones we had
        for _, n := range ns {
            nc[n] += c
        }
    }

    return nc
}
```

### Thoughts

Today's puzzle was all about finding the right way to represent the data. While the initial
slice-based approach worked, the frequency map solution was much more elegant and efficient. It's a
good reminder that sometimes you need to step back and rethink your approach when scaling becomes an
issue.

I'd rate this a 3/10 difficulty - the concept itself isn't particularly challenging, but recognizing
the need to optimize and implementing the frequency-based solution required some careful thinking.

_See you tomorrow!_

---

## Day 10: Hoof It

In today's Advent of Code puzzle, we were tasked with analyzing a topographic map of a hiking area
on a floating island. The map indicated the height of each position using a scale from 0 (lowest) to
9 (highest). Our goal was to find all the trailheads and calculate two different metrics for each
one.

For Part 1, we needed to find the trailheads (any position with a height of 0) and calculate a
"score" for each one. The score was defined as the number of positions with a height of 9 that were
reachable from that trailhead via a hiking trail. A hiking trail was any path that started at height
0, ended at height 9, and increased by exactly 1 in height at each step.

To solve this, I first parsed the input into a 2D grid representing the topographic map. I then
implemented a breadth-first search (BFS) algorithm, starting from each trailhead and exploring all
valid paths. Whenever I reached a height 9 position, I incremented the trailhead's score. The sum of
all the trailhead scores was the final answer for Part 1.

```go
func bfs(grid [][]int, start [2]int) int {
    directions := [][2]int{{0, 1}, {1, 0}, {0, -1}, {-1, 0}}
    queue := [][2]int{start}
    visited := make(map[[2]int]bool)
    visited[start] = true
    score := 0

    for len(queue) > 0 {
        curr := queue[0]
        queue = queue[1:]

        for _, d := range directions {
            ni, nj := curr[0]+d[0], curr[1]+d[1]
            if ni >= 0 && ni < len(grid) && nj >= 0 && nj < len(grid[0]) {
                next := [2]int{ni, nj}
                if !visited[next] && grid[ni][nj] == grid[curr[0]][curr[1]]+1 {
                    visited[next] = true
                    queue = append(queue, next)
                    if grid[ni][nj] == 9 {
                        score++
                    }
                }
            }
        }
    }

    return score
}
```

Part 2 introduced a new metric called the "rating" of a trailhead. The rating was defined as the
number of distinct hiking trails that began at that trailhead. To solve this, I used a recursive
depth-first search (DFS) approach, tracking the visited positions and direction at each step to
detect when a new valid trail was found.

```go
func countPaths(grid [][]int, pos [2]int, visited map[[2]int]bool) int {
    if grid[pos[0]][pos[1]] == 9 {
        return 1 // reached the end of a valid path
    }

    directions := [][2]int{{0, 1}, {1, 0}, {0, -1}, {-1, 0}}
    visited[pos] = true
    totalPaths := 0

    for _, d := range directions {
        ni, nj := pos[0]+d[0], pos[1]+d[1]
        next := [2]int{ni, nj}

        // check bounds and ensure path increment is valid
        if ni >= 0 && ni < len(grid) && nj >= 0 && nj < len(grid[0]) {
            if !visited[next] && grid[ni][nj] == grid[pos[0]][pos[1]]+1 {
                totalPaths += countPaths(grid, next, visited)
            }
        }
    }

    visited[pos] = false // backtrack
    return totalPaths
}
```

### Thoughts

Today's puzzle was an interesting challenge in graph traversal and state management. While the core
concepts weren't overly complex, implementing the solutions correctly and efficiently required some
careful thinking.

The trickiest part was definitely the transition from Part 1 to Part 2. Part 1's BFS approach was
relatively straightforward, but Part 2's DFS-based path counting introduced a lot more complexity.
Keeping track of the visited positions and direction changes to avoid duplicates was key, and it
took some debugging to get the recursive logic right.

Performance-wise, both solutions are reasonably efficient, with the BFS approach in Part 1 running
in $O(n^2)$ time and the DFS in Part 2 running in $O(n \* 3^n)$ time (where $n$ is the number of
positions in the grid). However, the memory usage for Part 2 could be a concern for larger inputs,
as we're recursively exploring all possible paths.

Overall, I'd rate this puzzle a 4/10 in difficulty. The concepts weren't overly complex, but the
implementation details and the transition from Part 1 to Part 2 added a decent challenge. It was a
good exercise in graph algorithms and state management, and I enjoyed the problem-solving aspect of
it.

_See you tomorrow!_

---

## Day 9: Disk Fragmenter

Today's puzzle was about helping an amphipod compact files on a disk. The challenge involved
interpreting a dense disk map format and implementing file movement algorithms. What made this
particularly interesting was the need to track file IDs and carefully manage block-by-block
movements in Part 1, then switch to whole-file movements in Part 2.

For Part 1, we needed to move individual blocks from the rightmost files to the leftmost free
spaces, maintaining file order and calculating a checksum based on positions. Here's how I
approached parsing the disk map and creating the initial state:

```go
type Disk struct {
    Blocks []int // -1 represents free space, non-negative numbers represent file IDs
}

func parseDiskMap(input string) ([]int, []int) {
    files := make([]int, 0)
    spaces := make([]int, 0)

    for i := 0; i < len(input); i++ {
        size := utils.AtoiNoErr(string(input[i]))
        if i%2 == 0 {
            files = append(files, size)
        } else {
            spaces = append(spaces, size)
        }
    }
    return files, spaces
}

func createInitialDisk(files, spaces []int) Disk {
    var blocks []int
    fileID := 0

    for i := 0; i < len(files); i++ {
        // add file blocks
        for j := 0; j < files[i]; j++ {
            blocks = append(blocks, fileID)
        }
        fileID++

        // add free space
        if i < len(spaces) {
            for j := 0; j < spaces[i]; j++ {
                blocks = append(blocks, -1)
            }
        }
    }

    return Disk{Blocks: blocks}
}
```

The core of Part 1 involved finding the rightmost file block and the leftmost free space, then
moving blocks one at a time:

```go
func (d *Disk) findFirstFreeSpace() int {
    for i, block := range d.Blocks {
        if block == -1 {
            return i
        }
    }
    return -1
}

func (d *Disk) findLastFileBlock() int {
    for i := len(d.Blocks) - 1; i >= 0; i-- {
        if d.Blocks[i] != -1 {
            return i
        }
    }
    return -1
}

func (d *Disk) moveOneBlock(fromIndex, toIndex int) {
    fileID := d.Blocks[fromIndex]
    d.Blocks[fromIndex] = -1
    d.Blocks[toIndex] = fileID
}
```

Part 2 changed things up significantly - instead of moving individual blocks, we needed to move
entire files at once, but only if there was enough continuous free space to the left. Files had to
be processed in decreasing order of file ID. This required new helper functions to find file sizes
and continuous free space:

```go
func (d *Disk) findFileSize(pos int) int {
    if pos < 0 || pos >= len(d.Blocks) || d.Blocks[pos] == -1 {
        return 0
    }

    fileID := d.Blocks[pos]
    start := pos
    // Find start of file
    for start >= 0 && d.Blocks[start] == fileID {
        start--
    }
    start++

    end := pos
    // Find end of file
    for end < len(d.Blocks) && d.Blocks[end] == fileID {
        end++
    }

    return end - start
}

func (d *Disk) findFreeSpaceSize(pos int) int {
    size := 0
    for i := pos; i < len(d.Blocks) && d.Blocks[i] == -1; i++ {
        size++
    }
    return size
}
```

One of the trickiest parts was managing the movement of whole files while ensuring we didn't
overwrite other files in the process:

```go
func (d *Disk) moveWholeFile(fromIndex, toIndex, size int) {
    fileID := d.Blocks[fromIndex]

    // Clear old location
    for i := 0; i < size; i++ {
        d.Blocks[fromIndex+i] = -1
    }

    // Place at new location
    for i := 0; i < size; i++ {
        d.Blocks[toIndex+i] = fileID
    }
}
```

### Thoughts

This puzzle was quite challenging, primarily because it required careful state management and
precise implementation of different movement strategies for each part. The main challenges were:

1. Understanding the dense disk map format and correctly translating it into a workable
   representation
2. Implementing the block-by-block movement logic for Part 1 while maintaining file integrity
3. Making the mental shift to whole-file movements in Part 2
4. Managing edge cases like ensuring continuous free space and processing files in the correct order

The biggest trap was assuming Part 2 would be more complex than Part 1 - while it required different
logic, moving whole files at once was actually simpler in some ways than the careful block-by-block
movements of Part 1. The key insight was realizing that Part 2's constraints actually made the
problem more deterministic, since files could only move if there was enough continuous free space to
their left.

I'd rate this an 7/10 difficulty. While the concepts weren't extremely complex, getting all the
details right and handling both parts correctly required careful thought and implementation. The
transition from Part 1 to Part 2 was particularly interesting, requiring a complete rethink of the
movement strategy while still maintaining the core disk state management.

_See you tomorrow!_

---

## Day 8: Resonant Collinearity

Today's puzzle was about antenna signals and finding special points called antinodes in a 2D grid.
Each antenna has a specific frequency (represented by a letter or digit), and antinodes form when
specific geometric conditions are met between antennas of the same frequency.

For Part 1, antinodes occur at any point that's collinear (in a straight line) with two antennas of
the same frequency, but only when that point is twice as far from one antenna as it is from the
other. I approached this by first parsing the grid and grouping antennas by frequency:

```go
type Grid [][]rune
type Position struct {
    x, y int
}

func getFrequencies(grid Grid) map[rune][]Position {
    frequencies := make(map[rune][]Position)
    for y := 0; y < len(grid); y++ {
        for x := 0; x < len(grid[y]); x++ {
            char := grid[y][x]
            if char != '.' { // ignores filler spaces
                frequencies[char] = append(frequencies[char], Position{x, y})
            }
        }
    }
    return frequencies
}
```

The core logic for finding antinodes involves checking if points are collinear and satisfy the
distance ratio requirement. To avoid floating-point precision issues, I used squared distances:

```go
func isAntinode(p, a, b Position) bool {
    if !isCollinear(p, a, b) {
        return false
    }

    // Calculate squared distances
    dap := distanceSquared(a, p)
    dbp := distanceSquared(b, p)

    // Check if either distance is twice the other
    // Note: We compare squares, so it's 4 times instead of 2 times
    return dap == 4*dbp || dbp == 4*dap
}
```

Part 2 introduced "resonant harmonics" which simplified the rules - an antinode now occurs at any
point that's collinear with two antennas of the same frequency, regardless of distance. This
actually made the calculation simpler, but required checking every grid position:

```go
if harmonic {
    // Part 2: Check every point in the grid for collinearity
    for y := 0; y < len(grid); y++ {
        for x := 0; x < len(grid[y]); x++ {
            p := Position{x, y}
            // Check if this point is collinear with any pair of antennas
            for i := 0; i < len(pos); i++ {
                for j := i + 1; j < len(pos); j++ {
                    if isCollinear(p, pos[i], pos[j]) {
                        antinodes[p] = true
                        break
                    }
                }
            }
        }
    }
}
```

### Thoughts

Today's puzzle was an interesting mix of geometry and efficient grid searching. The main challenges
were:

1. Getting the collinearity check right without running into floating-point precision issues
2. Efficiently calculating distances and ratios for Part 1
3. Managing the transition between the complex distance rules in Part 1 and the simpler but more
   computationally intensive Part 2
4. Keeping track of unique antinode positions when multiple antenna pairs might create antinodes at
   the same point

A key insight was using cross multiplication in the collinearity check to avoid division:

```go
func isCollinear(p, a, b Position) bool {
    dx1 := a.x - p.x
    dy1 := a.y - p.y
    dx2 := b.x - p.x
    dy2 := b.y - p.y
    return dx1*dy2 == dx2*dy1
}
```

I'd rate this a 6/10 difficulty - while the geometric concepts weren't too complex, implementing
them correctly and efficiently required careful thinking and good problem-solving skills. Part 2's
twist was clever, forcing us to rethink our approach even though it technically simplified the
problem.

_See you tomorrow!_

---

## Day 7: Bridge Repair

Today's puzzle was about evaluating arithmetic expressions with a twist. We needed to determine if
sequences of numbers could be combined using operators to produce specific target values. The catch?
Operators are evaluated strictly left-to-right (no precedence rules), and the numbers must be used
in their given order.

For Part 1, we had to work with addition (+) and multiplication (\*) operators. Each line in the
input contained a target value followed by a sequence of numbers. For example:

```

190: 10 19 3267: 81 40 27 292: 11 6 16 20

```

I approached this using backtracking to try all possible operator combinations. First, I created a
map to store the parsed input:

```go
func parseInput(input string) map[int][]int {
    calibrations := make(map[int][]int)
    for _, line := range strings.Split(input, "\n") {
        parts := strings.Split(line, ": ")
        key, _ := strconv.Atoi(parts[0])

        for _, val := range strings.Split(parts[1], " ") {
            val, _ := strconv.Atoi(val)
            calibrations[key] = append(calibrations[key], val)
        }
    }

    return calibrations
}
```

The core validation logic uses backtracking to try each possible operator at each position:

```go
var backtrack func(pos, curr int) bool
backtrack = func(pos, curr int) bool {
    // if we've used all the numbers, check if we hit the target
    if pos == len(vals) {
        return curr == target
    }

    // try addition
    if backtrack(pos+1, curr+vals[pos]) {
        return true
    }

    // try multiplication
    if backtrack(pos+1, curr*vals[pos]) {
        return true
    }

    return false
}
```

Part 2 introduced a new operator: concatenation (||). This operator joins the digits of two numbers
together (e.g., 12 || 345 = 12345). This required adding string manipulation to our solution:

```go
if tryConcat {
    // convert the current to a string, concat the next, convert back
    currStr := strconv.Itoa(curr)
    nextStr := strconv.Itoa(vals[pos])
    concatNum, _ := strconv.Atoi(currStr + nextStr)
    if backtrack(pos+1, concatNum) {
        return true
    }
}
```

The main function just calls the `parseInput` function then loops over each calibration and calls
`backtrack` with the target value:

```go
calibrations := parseInput(input)
validKeys := make([]int, 0)

for key, vals := range calibrations {
    if isCalibrationValid(key, vals, part == 2) {
        validKeys = append(validKeys, key)
    }
}

return utils.Sum(validKeys)
```

### Thoughts

Today's puzzle was a nice mix of arithmetic and string manipulation. The main challenge was handling
the left-to-right evaluation requirement and implementing the backtracking solution efficiently. The
addition of the concatenation operator in Part 2 added an interesting twist, requiring careful
string manipulation and handling of larger numbers.

The key insight was recognizing this as a backtracking problem where we try different operators at
each position. While we could potentially optimize further with caching or pruning, the current
solution provides a good balance between clarity and performance.

I'd rate this a 2/10 difficulty - not overly complex, but requires some careful implementation. I
saw some other people were having issues with their sum being higher than what a 32-bit integer can
hold, luckily I didn't have that issue, idk why lol.

_See you tomorrow!_

## Day 6: Guard Gallivant

Today's puzzle involved simulating a guard's patrol path in a grid-based map and predicting their
movements. The input consists of a grid where `^` represents the guard's starting position (facing
up) and `#` represents obstacles.

For Part 1, we needed to calculate how many distinct positions the guard would visit before leaving
the mapped area. The guard follows a simple protocol:

-   If there's an obstacle in front, turn right 90 degrees
-   Otherwise, move forward one step

My solution uses a Point and Direction system to track the guard's movement through the grid:

```go
type Point struct {
    x, y int
}

type Direction struct {
    dx, dy int
}

type Guard struct {
    pos Point
    dir Direction
}
```

Then we simulate the guard's movement using a map to track visited positions and implement the
protocol:

```go
func simulateGuardPath(grid [][]byte, guard Guard, checkLoop bool) int {
    visited := make(map[Point]bool)
    visited[guard.pos] = true

    for {
        next := Point{
            x: guard.pos.x + guard.dir.dx,
            y: guard.pos.y + guard.dir.dy,
        }

        if !isInBounds(next, grid) {
            break
        }

        if grid[next.y][next.x] == '#' {
            guard.turnRight()
            continue
        }

        guard.pos = next
        visited[guard.pos] = true
    }

    return len(visited)
}
```

Part 2 flipped the problem around - we needed to find positions where placing a new obstacle would
cause the guard to get stuck in a loop. This required modifying our simulation to detect repeated
states (position + direction combinations):

```go
type State struct {
    pos Point
    dir Direction
}

func simLoop(grid [][]byte, guard Guard) int {
    start := guard.pos
    count := 0

    for y := range grid {
        for x := range grid[y] {
            if grid[y][x] != '.' || (Point{x, y} == start) {
                continue
            }

            // create a copy of the grid with the new obstruction
            newGrid := make([][]byte, len(grid))
            for i := range grid {
                newGrid[i] = make([]byte, len(grid[i]))
                copy(newGrid[i], grid[i])
            }
            newGrid[y][x] = '#'

            if simulateGuardPath(newGrid, guard, true) > 0 {
                count++
            }
        }
    }
    return count
}
```

### Thoughts

Today's puzzle was a deceptively complex challenge in path simulation and state management. While
the initial rules seemed straightforward, implementing them correctly and especially handling Part 2
required significant problem-solving and careful debugging.

The trickiest aspects included:

1. Getting the turn mechanics exactly right - the subtle interplay between direction changes and
   movement needed precise implementation
2. Understanding that Part 2 wasn't just about finding places to put obstacles, but about finding
   positions that would create perfect loops
3. Realizing that detecting loops required tracking the complete state (position AND direction)
   because the same position could be visited multiple times in different directions as part of a
   valid patrol route
4. Managing the complexity of copying grids and running simulations for every possible obstacle
   position in Part 2 without missing edge cases

A key insight that took some time to reach was that the loop detection needed to look at the full
state of the guard - just tracking visited positions wasn't enough. This realization led to
implementing the State struct to capture both position and direction:

```go
type State struct {
    pos Point
    dir Direction
}
```

Performance-wise, Part 2 involves simulating the guard's path for every possible obstacle position,
which means we're doing a lot of grid copying and path simulation. While there might be cleverer
ways to optimize this by analyzing patterns in the guard's movement, sometimes the straightforward
approach, even if computationally intensive, is the most reliable path to a solution.

I'd rate this a 6/10 difficulty - while the core concepts aren't overly complex, getting all the
pieces working together correctly required solid problem-solving skills and careful debugging. The
leap from Part 1 to Part 2 was particularly challenging, requiring a fundamental shift in how we
thought about the problem and tracked the guard's state

_See you tomorrow!_

---

## Day 5: Print Queue

Today's puzzle involved managing a print queue for safety manual updates using topological sorting.
The input consisted of rules about page ordering (in the form X|Y meaning page X must be printed
before page Y) and sequences of pages that needed to be printed.

Part 1 required checking if given sequences of pages satisfied all the applicable ordering rules.
For example, if we had rules like `47|53` and `75|29`, we needed to verify that page 47 came before
53 and page 75 came before 29 in each sequence. My solution uses a directed graph to represent these
dependencies:

```go
func buildGraph(rules []Rule) Graph {
    graph := make(Graph)
    for _, rule := range rules {
        graph[rule.before] = append(graph[rule.before], rule.after)
    }
    return graph
}
```

Then for each squence, I check if it satisfies all applicable rules by tracking page positions and
verifying dependencies:

```go
func isValidSequence(seq []int, graph Graph) bool {
    positions := make(map[int]int)
    for i, page := range seq {
        positions[page] = i
    }

    for i := 0; i < len(seq); i++ {
        page := seq[i]
        if after, exists := graph[page]; exists {
            for _, mustBeAfter := range after {
                if pos, exists := positions[mustBeAfter]; exists {
                    if pos <= i {
                        return false
                    }
                }
            }
        }
    }
    return true
}
```

Part 2 flipped the problem around - instead of just validating sequences, we needed to correctly
order the invalid sequences using Kahn's topological sorting algorithm. This required tracking
in-degrees for each node and carefully managing the order of processing to match the expected
output:

```go
func topologicalSort(pages []int, fullGraph Graph) []int {
    // Create subgraph with only relevant pages...
    nodes := make(map[int]*Node)
    // Build dependencies...
    // Process queue in correct order...
    // Return sorted sequence...
}
```

Topological sort is a long algorithm in Go, so I didn't write it all here, but the full solution is
available on my [GitHub](https://github.com/dickeyy/adventofcode/blob/main/2024/day-5/main.go).

### Thoughts

Today's puzzle was a nice application of graph theory and topological sorting. While the core
concept wasn't too complex, getting all the edge cases right and ensuring the correct ordering in
Part 2 required careful implementation.

The trickiest part was handling Part 2's requirement to generate valid orderings. Making sure the
topological sort produced the correct ordering when multiple valid orderings were possible took some
debugging to get right. The key insight was realizing we needed to carefully manage the queue order
to ensure deterministic output.

The problem was also a good reminder of how important it is to properly model the problem space -
representing the dependencies as a directed graph made both parts much more straightforward to
solve.

I'd rate this a 5/10 difficulty - not overly complex conceptually, but requiring solid understanding
of graph algorithms and attention to detail in the implementation.

_See you tomorrow!_

---

## Day 4: Ceres Search

Today's puzzle was an interesting twist on the classic word search problem. Instead of searching for
a single instance of "XMAS", we needed to find all possible occurrences in Part 1, and then pivot to
finding X-shaped "MAS" patterns in Part 2.

There's quite a bit of code for today, so I'm not going to include it all here. As always, the full
solution is available on my
[GitHub](https://github.com/dickeyy/adventofcode/blob/main/2024/day-4/main.go).

For Part 1, I implemented a grid search that looks for "XMAS" in all eight possible directions
(horizontal, vertical, and diagonal) from any starting position. The approach uses direction vectors
to check each possible orientation:

```go
var dirs = []Direction{
    {0, 1},   // right
    {0, -1},  // left
    {1, 0},   // down
    {-1, 0},  // up
    {1, 1},   // down-right
    {1, -1},  // down-left
    {-1, 1},  // up-right
    {-1, -1}, // up-left
}
```

Part 2 required a different approach since we needed to find X-shaped patterns where each diagonal
spells either "MAS" or "SAM". I optimized this by only checking positions that contain 'A' (the
center of the X) and then validating the diagonals:

```go
if grid[row][col] == 'A' {
    if checkXMASCross(grid, row, col, rows, cols) {
        count++
    }
}
```

### Thoughts

Today's puzzle was quite the step up from the last one (in my opinion). While grid traversal and
pattern matchiing might sound straightforward, implementing both parts correctly required careful
thought and precise implementation.

The part that really made thhis puzzle tricky was handling all the edge cases correcly. In part 1,
ensuring the pattern checking worked in all eight directions while staying within bounds took some
debugging to get right. The pattern validation logic needed to be both efficient and thorough since
we were looking for all possible instances of "XMAS".

Part 2's X-pattern search was even more devious - it fundamentally changed how we needed to think
about the problem. The realization that we could optimize by starting from 'A' positions helped, but
validating the diagonal patterns correctly and handling the fact that "MAS" could be reversed added
extra complexity. Plus, the way the puzzle description led us to initially think about it in terms
of overlapping "MAS" strings, when really it was about finding X-shaped patterns, was quite clever.

Performance-wise, while both parts run quickly thanks to the optimized starting positions (X/A),
getting there required several refactoring attempts to handle all cases correctly while maintaining
efficiency.

I'd rate this a 5/10 difficulty - definitely more challenging than the first three days and
requiring some solid problem-solving skills to implement correctly. The misdirection in Part 2 and
the need for precise pattern matching logic made this a satisfyingly complex puzzle.

_See you tomorrow!_

---

## Day 3: Mull it Over

Today's puzzle was about parsing corrupted computer memory and extracting valid multiplication
instructions. The input consists of strings containing `mul(x,y)` patterns mixed with various
invalid characters and conditionals. Essentially it's a whole bunch of regex.

For part 1, you must find the number of valid `mul` instructions (where $x$ and $y$ are 1-3 digit
integers) and sum up their products. For example:

```
xmul(2,4)mul[3,7]a2mul(4,3)
```

Would be `(2*4) + (4*3) = 20`.

Only the properly formatted `mul(x,y)` patterns count. My solution uses regex to extract these
patters:

```go
func getMulNums(input string) [][]int {
    muls := make([][]int, 0)
    re := regexp.MustCompile(`mul\((\d+),(\d+)\)`)
    matches := re.FindAllStringSubmatchIndex(input, -1)

    // go on to process each match ...
}
```

You then just need to sum up the products of each pair.

Part 2 introduces conditional logic with `do()` and `don't()` instructions that enable or disable
multiplication operations. I modified the regex pattern to capture these new instructions and added
a boolean flag to track whether multiplications should be processed.

For this part, I just modified the regex pattern to capture these new instructions, added a
conditional boolean to the `getMulNums` function, and then added an `allowMul` boolean which (if the
conditional is true) would process the `do()` and `dont()` instructions.

```go
func getMulNums(input string, conditional bool) [][]int {
    // ...
    re := regexp.MustCompile(`mul\(\d+,\d+\)|do\(\)|don't\(\)`) // new regex
    // ...

    allowMul := true

	for _, match := range matches {
		op := input[match[0]:match[1]]

        // this part only happens if we are doing part 2
		if conditional {
			if op == "do()" {
				allowMul = true
			} else if op == "don't()" {
				allowMul = false
			}
		}

        // slightly modified from before due to the new conditional
		if allowMul && strings.HasPrefix(op, "mul") {
			muls = append(muls, extractNumsFromMul(op))
		}
	}

	return muls
}
```

Aside from these updates, I also made a `extractNumsFromMul` function to make my code a bit easier
to read:

```go
func extractNumsFromMul(op string) []int {
	numRe := regexp.MustCompile(`(\d+)`)
	nums := numRe.FindAllStringSubmatch(op, -1)
	x, _ := strconv.Atoi(nums[0][1])
	y, _ := strconv.Atoi(nums[1][1])
	return []int{x, y}
}
```

As always, the full solution is available on my
[GitHub](https://github.com/dickeyy/adventofcode/blob/main/2024/day-3/main.go).

### Thoughts

Today was an interesting exercise in string parsing and regex. While the core logic wasn't too
complex, getting the regex patterns right and handling the conditional state properly required some
careful thinking.

The biggest challenge was probably crafting the regex pattern to capture both the multiplication
instructions and the conditional statements while ignoring all the noise characters.

I'd rate this a 2/10 difficulty - not particularly difficult, just some clever regex.

_See you tomorrow!_

---

## Day 2: Red-Nosed Reports

Not too bad today to be honest. I got both parts done in < 45 minutes after I started, which
included an algorithm rewrite is not too bad for me.

Today's problem was about processing a $\mathbb{R}^{m\times n}$ matrix of integers. Each row is a
list of "levels". For each row, you need to verify it passes a few rules:

1. The row can only increase OR decrease, no switching part way through.
2. The difference between two consecutive levels must be between 1 and 3 (inclusive).

For part 1, you need to sum up the number of passing rows (rows that pass the above rules). For
example,

```
7 6 4 2 1
1 2 7 8 9
9 7 6 2 1
1 3 2 4 5
8 6 4 4 1
1 3 6 7 9
```

Has 2 safe rows (rows 1 and 6). Part 1 is pretty simple, once you have a working algorithm. Mine
looks like this:

```go
func isValidRow(row []int) bool {
    if len(row) < 2 {
        return true
    }

    // determine the initial direction from the first 2 nums
    isInc := row[1] > row[0]

    // check first pair meets difference criteria
    initialDiff := utils.Abs(row[1] - row[0])
    if initialDiff < 1 || initialDiff > 3 {
        return false
    }

    // check remaining pairs
    for i := 1; i < len(row)-1; i++ {
        curr, next := row[i], row[i+1]
        diff := next - curr

        // if direction changes, sequence is invalid
        if (diff > 0) != isInc {
            return false
        }

        // check the diff is within bounds
        if utils.Abs(diff) < 1 || utils.Abs(diff) > 3 {
            return false
        }
    }
    return true
}
```

_Note: `utils.Abs` is a helper function that can take in `int` rather than the `math.Abs` function
which takes in `float64`._

Go through each row in the matrix, if it is valid, increment the counter. Easy peasy.

For part 2, if a row is invalid, you need to now check if you can make it valid by removing any 1
level from the row. For example, the above matrix now has 4 safe rows (rows 1, 4, 5, and 6). I had
trouble figuring out how to do this efficiently, so it took some time, but I eventually came up with
this:

```go
func canBecomeValid(row []int) bool {
    // try removing each num and check if the resulting row is valid
    for i := range row {
        // create a new slice without the current num
        newRow := make([]int, 0, len(row)-1)
        newRow = append(newRow, row[:i]...)
        newRow = append(newRow, row[i+1:]...)

        if isValidRow(newRow) {
            return true
        }
    }
    return false
}
```

This just checks if a given row can become valid by removing any 1 level from the row, it tests
every number and then returns true if it can. You then modify the main function a bit for part 2 to
check if either `isValidRow` or `canBecomeValid` returns true, if so, increment the counter. Done!

### Thoughts

Today was a pretty cool problem. It seems trivial at first but then there are a few things that
catch you off guard. Still, relatively easy though, it will get harder the further into the month we
go.

This algorithm would be much easier in Python using `zip` and even day 1 would be easier with this
same function. I may write a `Zip2` function in Go as a util in the future since it's 2 days in a
row that my life would be so much easier. That said, this algorithm works and is still pretty fast.
Both parts ran in < 600 µs on my server. The point of AoC (for me) is not to write the most
efficient algorithm possible and not to get on the leaderboard, but to learn and improve. From doing
AoC for the past few years, I've learned a lot about algorithms and data structures, and in my book,
that's a win.

Overall, I'd give this a 3/10 difficulty, simply because it was a bit of work to find a
semi-efficient solution for part 2.

_See you tomorrow!_

---

## Day 1: Historian Hysteria

First day of AoC 2024! This year I decided to do all my solutions in [Go](https://golang.org).

Today's problem was pretty easy. You're given a list of integers, 2 in each row (separated by 3
spaces).

For part 1, you need to pair the smallest number on the left with the smallest on the right, then
the second smallest, then the third, and so on. For example,

```
1   4
3   1
4   3
8   2
```

Would be paired as `(1, 1), (3, 2), (4, 3), (8, 4)`. Then, you need to sum up the differences
between each pair. With the above example, the sum would be `0 + 1 + 1 + 4 = 6`.

My approach for part 1 was to first separate the numbers into two lists `left` and `right`, sort
them, and iterate over the left list calculating the absolute difference between each pair. Since we
know the right list is the same length as the left, we can just iterate over one and associate the
index with the other.

```go
left := make([]int, 0)
right := make([]int, 0)

// parse input ...

sort.Ints(left)
sort.Ints(right)

for i := 0; i < len(left); i++ {
    out += int(math.Abs(float64(left[i] - right[i])))
}
```

Pretty easy!

For part 2, you need to multiply each number in the left list by the number of times it appears in
the right list and sum up the results. For the above example, the result would be
`(1 * 1) + (3 * 1) + (4 * 1) + (8 * 1) = 16`.

My approach in part 2 was to make a hashmap of the right list associating each number with its
frequency, then iterate over the left list and multiply each number by its frequency in the hashmap.

```go
freq := make(map[int]int)
for _, num := range right {
    freq[num]++
}

for _, num := range left {
    if f, exists := freq[num]; exists {
        out += num * f
    }
}
```

For this part, you could use a nested for loop, but I wanted it to be a bit faster. The nested for
loop is O(n^2), whereas the hashmap is O(n).

### Thoughts

Super easy today. Looking back on last year's day 1 problem, this was a walk in the park. I had fun
optimizing my solution, and yes, I know it's not the most efficient algorithm, but it's easy to
understand and it works.

Overall, today was pretty easy, about a 1/10 difficulty.

_See you tomorrow!_
